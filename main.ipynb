{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# RNN with LSTM for Predictive Traffic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "source": [
    "## Preparing the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Defining network structure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, n_layers, n_traffic):\n",
    "        super(RNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, n_layers, batch_first=False)\n",
    "        # -> x of shape (seq_len, batch, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, n_traffic)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # initial hidden- & cell-state\n",
    "        h0 = torch.zeros(self.n_layers, x.size(1), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.n_layers, x.size(1), self.hidden_size).to(device)\n",
    "\n",
    "        # output of shape (seq_len, batch, n_directions * hidden_size)\n",
    "        out, _ = self.lstm(x, (h0,c0))\n",
    "        \n",
    "        # only last Time-Step\n",
    "        out = out[-1, :, :]\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        out = self.softmax(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "source": [
    "## Defining helper functions for neural networs's training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(file_tensor, character_tensor):\n",
    "    output = model(file_tensor)\n",
    "    loss = criterion(output, traffic_tensor)\n",
    "    # traffic_tensor -> \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return output, loss.item()\n",
    "\n",
    "def traffic_from_output(output):\n",
    "    traffic_idx = torch.argmax(output).item()\n",
    "    return traffic_idx"
   ]
  },
  {
   "source": [
    "## Defining hyperparameters of neural network's training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "input_size = 7 # features\n",
    "n_traffic = 10 # output_size\n",
    "hidden_size = 128\n",
    "n_layers = 1\n",
    "\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "source": [
    "## Start training loop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize neural network   \n",
    "model = RNN(input_size, hidden_size, n_layers, n_traffic).to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "n_iters = 50000\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(1, n_iters + 1):\n",
    "    #character, file, character_tensor, file_tensor = random_training_example(character_files, all_characters)\n",
    "    output, loss = train(file_tensor.to(device), character_tensor.to(device))\n",
    "    current_loss += loss\n",
    "    \n",
    "    # print iter number, loss, name and guess\n",
    "    if i % print_every == 0:\n",
    "        guess = character_from_output(output)\n",
    "        correct = '✓' if guess == character else '✗ (%s)' % character\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (i, i / n_iters * 100, timeSince(start), loss, file, guess, correct))\n",
    "\n",
    "    # add current loss avg to list of losses\n",
    "    if i % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  },
  {
   "source": [
    "## Plot LOSS-function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure\n",
    "mpl.style.use(\"seaborn-whitegrid\")\n",
    "plt.figure(figsize=(12,6))\n",
    "# create plot\n",
    "plt.plot(all_losses)\n",
    "# title and labels\n",
    "plt.title(\"LOSS-function\", fontsize=20)\n",
    "plt.xlabel(\"iterations\", fontsize=15)\n",
    "plt.ylabel(\"loss\", fontsize=15)\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Save model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"model.pth\"\n",
    "torch.save(model.state_dict(), FILE)"
   ]
  },
  {
   "source": [
    "## Load Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"model.pth\"\n",
    "loaded_model = RNN(input_size, hidden_size, n_layers, n_characters).to(device)\n",
    "loaded_model.load_state_dict(torch.load(FILE, map_location=device))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "source": [
    "## Determin accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "character_files, all_characters = load_data(subfolder=\"test\")\n",
    "print(\"characters in test data: \", all_characters)\n",
    "\n",
    "# keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(n_characters, n_characters)\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    for character in all_characters:\n",
    "        # all files from one character\n",
    "        for file in character_files[character]:\n",
    "            file_tensor = file_to_tensor(file).to(device)\n",
    "            # get output\n",
    "            output = loaded_model(file_tensor).to(device)\n",
    "            # get character from output\n",
    "            guess = character_from_output(output)\n",
    "            n_samples += 1\n",
    "            if guess == character:\n",
    "                n_correct += 1\n",
    "                correct = \"✓\"\n",
    "            else:\n",
    "                correct = \"✗ (%s)\" % character\n",
    "            confusion[all_characters.index(character)][all_characters.index(guess)] += 1\n",
    "            \n",
    "            print(file, \"/\", guess, correct)\n",
    "\n",
    "# normalize by dividing every row by its sum\n",
    "for i in range(n_characters):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f\"\\naccuracy = {acc:.2f} %\\n\")\n",
    "\n",
    "# set up plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# set up axes\n",
    "ax.set_xticklabels([''] + all_characters, rotation=90)\n",
    "ax.set_yticklabels([''] + all_characters)\n",
    "\n",
    "# force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  }
 ]
}